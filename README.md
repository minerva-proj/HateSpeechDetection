# Text classification and develop skills in data pre-processing, feature engineering, model selection, and evaluation
Text classification is a critical task in natural language processing, with several practical applications including sentiment analysis, spam detection, and hate speech detection. It entails categorising text based on its content into specified categories. With the increased availability of digital data, the need for accurate and efficient text classification algorithms is greater than ever.
The goal of this project is to create, construct, and test a text classifier that can accurately categorise text data from the OLID dataset. This dataset has a wide spectrum of inflammatory language and hate speech content, making text categorization algorithms work hard. By completing this project, we hope to gain a better understanding of the practical challenges of text classification and develop a model that can be used to improve automated content moderation in social media and other digital platforms.

The first method involved using a Support Vector Machine (SVM) classifier, which is a widely used algorithm for text classification tasks. The tweets were initially tokenized with NLTK, and then stopword removal, stemming, and TF-IDF vectorization were applied. Stopword reduction is deleting frequent terms like "the," "a," and "is" that have little meaning in the text. Stemming is the process of reducing words to their simplest form, such as "running" to "run." The text data was then transformed using the Term Frequency-Inverse Document Frequency (TFIDF) vectorizer, which is a popular technique for converting text into numerical features that can be used in machine learning algorithms.
The second method involved using a Bidirectional Long Short-Term Memory (BiLSTM) model, which is a type of neural network that can capture the context and dependencies between words in a sentence. The data was preprocessed using NLTK and tokenized using the TensorFlow tokenizer. The tokenized data was then passed through the BiLSTM model, which learned to classify the text data into the relevant categories.
The third method also used a BiLSTM model, but instead of using the TensorFlow tokenizer, the text data was preprocessed using NLTK and transformed using the TFIDF vectorizer. This allowed for a different approach to encoding the text data as numerical features, which I believed could potentially improve the classification performance of the model
